{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdDepictor\n",
    "\n",
    "from evaluation_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import literature dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/literature-dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canonicalize the SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMILES'] = df['SMILES'].apply(lambda x: Chem.MolToSmiles(Chem.MolFromSmiles(x), isomericSmiles=True, kekuleSmiles=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate source SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(smiles):\n",
    "    substitutions = {\n",
    "        r'\\[K[@,H]*\\]': '[K]',\n",
    "        r'\\[B[@,H]*\\]': 'B',\n",
    "        r'\\[Na[@,H,+,-]*\\]': '[Na]',\n",
    "        r'\\[C[@,H]*\\]': 'C',\n",
    "        r'\\[N[@,H]*\\]': 'N',\n",
    "        r'\\[O[@,H]*\\]': 'O',\n",
    "        r'\\[S[@,H]*\\]': 'S',\n",
    "        r'\\[P[@,H]*\\]': 'P',\n",
    "        r'\\[F[@,H]*\\]': 'F',\n",
    "        r'\\[Cl[@,H]*\\]': '[Cl]',\n",
    "        r'\\[Br[@,H]*\\]': '[Br]',\n",
    "        r'\\[I[@,H]*\\]': 'I',\n",
    "        r'@': '',\n",
    "        r'/': '',\n",
    "        r'\\\\': ''\n",
    "    }\n",
    "\n",
    "    for pattern, replacement in substitutions.items():\n",
    "        smiles = re.sub(pattern, replacement, smiles)\n",
    "\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df['SMILES'].apply(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smi_tokenizer(smi: str) -> str:\n",
    "        \"\"\"\n",
    "        Tokenize a SMILES molecule or reaction. Modified for the special tagging character \"!\".\n",
    "        \"\"\"\n",
    "        pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\!|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "        regex = re.compile(pattern)\n",
    "        tokens = [token for token in regex.findall(smi)]\n",
    "        return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df['source'].apply(smi_tokenizer)\n",
    "df['target'] = df['SMILES'].apply(smi_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export source and target tokenized SMILES as text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'].to_csv('data/opennmt/validation/source.txt', index=False, header=False)\n",
    "df['target'].to_csv('data/opennmt/validation/target.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions using the 5x augmented model. Save verbose output in a log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = io.StringIO()\n",
    "\n",
    "with contextlib.redirect_stdout(buffer):\n",
    "    !onmt_translate -model models/not_augmented/not_augmented_step_200000.pt -src data/opennmt/validation/source.txt -output data/opennmt/validation/predictions.txt -n_best 1 -beam_size 1 -verbose\n",
    "\n",
    "output = buffer.getvalue()\n",
    "with open(\"data/opennmt/validation/log.txt\", \"w\") as file:\n",
    "    file.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to parse log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob_to_confidence(log_prob):\n",
    "    return math.exp(log_prob)\n",
    "\n",
    "def read_log_file(file_path): \n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "\n",
    "    predictions = []\n",
    "    scores = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r'^PRED \\d+:\\s*', line):\n",
    "            prediction = re.split(r'^PRED \\d+:\\s*', line, maxsplit=1)[1]\n",
    "            predictions.append(prediction)\n",
    "        elif line.startswith('PRED SCORE'):\n",
    "            score = float(line.split('PRED SCORE: ')[1].strip())\n",
    "            scores.append(log_prob_to_confidence(score))\n",
    "    \n",
    "    return predictions, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add predictions to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, scores = read_log_file('data/opennmt/validation/log.txt')\n",
    "\n",
    "df['prediction'] = predictions\n",
    "df['confidence'] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df['source'].apply(lambda x: x.replace(' ', ''))\n",
    "df['target'] = df['target'].apply(lambda x: x.replace(' ', ''))\n",
    "df['prediction'] = df['prediction'].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add weighted accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['top1_wt'] = df.apply(lambda x: chirality_weighted_accuracy(x['target'], x['prediction']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the structures of the target and the predicted SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('data/literature-dataset-pred.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chiralpred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
