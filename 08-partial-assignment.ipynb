{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import contextlib\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdDepictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import literature dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/coconut/coconut_incomplete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canonicalize the SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['smiles'] = df['smiles'].apply(lambda x: Chem.MolToSmiles(Chem.MolFromSmiles(x), isomericSmiles=True, kekuleSmiles=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smi_tokenizer(smi: str) -> str:\n",
    "        \"\"\"\n",
    "        Tokenize a SMILES molecule or reaction. Modified for the special tagging character \"!\".\n",
    "        \"\"\"\n",
    "        pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\!|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "        regex = re.compile(pattern)\n",
    "        tokens = [token for token in regex.findall(smi)]\n",
    "        return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df['smiles'].apply(smi_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export source and target tokenized SMILES as text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'].to_csv('data/opennmt/partial/source.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions using the 5x augmented model. Save verbose output in a log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!onmt_translate -model models/partial_augmented_5x/partial_augmented_5x_step_100000.pt -src data/opennmt/partial/source.txt -output data/opennmt/partial/predictions.txt -n_best 1 -beam_size 1 -verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add predictions to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv('data/opennmt/partial/predictions.txt', header=None, sep='\\t')\n",
    "df['prediction'] = predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df['source'].apply(lambda x: x.replace(' ', ''))\n",
    "df['prediction'] = df['prediction'].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate PDF report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_mol'] = df['source'].apply(Chem.MolFromSmiles)\n",
    "\n",
    "df['prediction_mol'] = df['prediction'].apply(Chem.MolFromSmiles)\n",
    "df = df.dropna(subset=['prediction_mol'])\n",
    "\n",
    "df = df[['identifier', 'source', 'prediction', 'source_mol', 'prediction_mol']]\n",
    "\n",
    "def mol_to_img_base64(mol, size=(400, 400)):\n",
    "    img = Draw.MolToImage(mol, size=size)\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    return f'<img src=\"data:image/png;base64,{img_str}\" width=\"{size[0]}\" height=\"{size[1]}\"/>'\n",
    "\n",
    "df['source_img'] = df['source_mol'].apply(lambda mol: mol_to_img_base64(mol))\n",
    "df['prediction_img'] = df['prediction_mol'].apply(lambda mol: mol_to_img_base64(mol))\n",
    "\n",
    "html_content = HTML(df.to_html(escape=False))\n",
    "with open('partial_assignments.html', 'w') as f:\n",
    "    f.write(html_content.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected examples:\n",
    "\n",
    "- CNP0107513.0\n",
    "- CNP0107664.0\n",
    "- CNP0107730.0\n",
    "- CNP0108208.0\n",
    "- CNP0213983.0\n",
    "- CNP0215345.0\n",
    "- CNP0216125.0\n",
    "- CNP0375995.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chiralpred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
